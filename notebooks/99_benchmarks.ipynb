{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable this to download the file if not already present\n",
    "\n",
    "#!wget http://s3.amazonaws.com/open.source.geoscience/open_data/newzealand/Taranaiki_Basin/Keri_3D/Kerry3D.segy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import vectorize, cuda\n",
    "from struct import unpack\n",
    "from ibm2ieee import ibm2float32 as i2f\n",
    "import segyio\n",
    "from segyio import _segyio\n",
    "import cupy as cp\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/greg/Projects/pydata-segy/')\n",
    "from segytools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadBinHdr(object):\n",
    "\n",
    "    ''' Read binary trace header for a trace '''\n",
    "\n",
    "    def __init__(self, bh):\n",
    "        if len(bh) != 400:\n",
    "            print(\"Binary header should be 400 bytes long\")\n",
    "        else:\n",
    "            self.jobid = unpack(\">i\", bh[0:4])[0]\n",
    "            self.line = unpack(\">i\", bh[4:8])[0]\n",
    "            self.reel = unpack(\">i\", bh[8:12])[0]\n",
    "            self.numtrcens = unpack(\">h\", bh[12:14])[0]\n",
    "            self.numauxtrcs = unpack(\">h\", bh[14:16])[0]\n",
    "            self.sampint = unpack(\">h\", bh[16:18])[0]\n",
    "            self.sampint2 = unpack(\">h\", bh[18:20])[0]\n",
    "            self.samppertrc = unpack(\">h\", bh[20:22])[0]\n",
    "            self.samppertrc2 = unpack(\">h\", bh[22:24])[0]\n",
    "            self.datasampcode = unpack(\">h\", bh[24:26])[0]\n",
    "            self.ensfold = unpack(\">h\", bh[26:28])[0]\n",
    "            self.sortcode = unpack(\">h\", bh[28:30])[0]\n",
    "            self.dis_units = unpack(\">h\", bh[54:56])[0]\n",
    "            self.segyformat = unpack(\">h\", bh[300:302])[0] // 256\n",
    "            self.lengthflag = unpack(\">h\", bh[302:304])[0]\n",
    "            self.numexthdrs = unpack(\">h\", bh[304:306])[0]\n",
    "    \n",
    "class ReadTrcHdr(object):\n",
    "    ''' Read Trace header '''\n",
    "    def __init__(self, bh):\n",
    "        if len(bh) != 240:\n",
    "            print(\"Trace Header should be 240 bytes long\")\n",
    "        else:\n",
    "            self.inline = unpack(\">i\", bh[220:224])[0]\n",
    "            self.xline = unpack(\">i\", bh[20:24])[0]\n",
    "            self.sou_x = unpack(\">i\", bh[72:76])[0]\n",
    "            self.sou_y = unpack(\">i\", bh[76:80])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hdrs = []\n",
    "trcs = []\n",
    "with open(\"Kerry3D.segy\",\"rb\") as f:\n",
    "    EBCDIC = f.read(3200)\n",
    "    BIN = ReadBinHdr(f.read(400))\n",
    "    samples_per_trace = BIN.samppertrc\n",
    "    sample_interval = BIN.sampint\n",
    "    idx=1\n",
    "    print(\"Starting loop....\")\n",
    "    while True:\n",
    "        tmp = f.read(240)\n",
    "        if not tmp:\n",
    "            print(\"End scanning .......\")\n",
    "            break\n",
    "        hdr = ReadTrcHdr(tmp).__dict__\n",
    "        trc = f.read(samples_per_trace*4)\n",
    "#         arr = ibmtoieee(np.frombuffer(trc,dtype='>u4'))\n",
    "        hdrs.append(hdr)\n",
    "        trcs.append(trc)\n",
    "        idx+=1\n",
    "data = trcs[10000] #data to perform analysis on\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the Cuda Kernel code that runs on every unsigned int in array\n",
    "ibm32cupy = cp.RawKernel(r'''\n",
    "extern \"C\" __global__\n",
    "void ibm32cupy(const unsigned int* x1, float* y) {\n",
    "    int tid = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "    unsigned int x = x1[tid];\n",
    "    if (x != 0){\n",
    "        int sign = ((x1[tid] >> 31) & 0x01) * (-2) + 1;\n",
    "        int exponent = (x1[tid] >> 24) & 0x7F;\n",
    "        int tmp = 4 * (exponent - 64);\n",
    "        double p;\n",
    "        if (tmp < 0) {\n",
    "            int po2 = 1 << (abs(tmp));\n",
    "            p = (double)(1.0/po2);\n",
    "        }\n",
    "        else{\n",
    "            p = 1 << tmp;\n",
    "        }\n",
    "        int mantissa = x1[tid] & 0x00ffffff;\n",
    "        float frac = ((float)mantissa / 0x1000000);\n",
    "        y[tid] = sign * frac * p;\n",
    "    }\n",
    "    else{\n",
    "        y[tid] = 0.0;\n",
    "    }    \n",
    "}\n",
    "''', 'ibm32cupy')\n",
    "# vectorized version of regular python function\n",
    "@vectorize(['float32(uint32)'])\n",
    "def ibmpy_vec(data):\n",
    "    if data == 0:\n",
    "        return 0.0\n",
    "    sign = data >> 31 & 0x01\n",
    "    exponent = data >> 24 & 0x7f\n",
    "    mantissa = (data & 0x00ffffff) / float(pow(2, 24))\n",
    "    return (1 - 2 * sign) * mantissa * pow(16.0, exponent - 64)\n",
    "\n",
    "#reguar python\n",
    "def ibmpython(data):\n",
    "    if data == 0:\n",
    "        return 0.0\n",
    "    sign = data >> 31 & 0x01\n",
    "    exponent = data >> 24 & 0x7f\n",
    "    mantissa = (data & 0x00ffffff) / float(pow(2, 24))\n",
    "    return (1 - 2 * sign) * mantissa * pow(16.0, exponent - 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intuitive first attempt of converting. apply a function to every element of an array in loop\n",
    "%timeit np.array([ibmpython(x) for x in np.frombuffer(data,dtype=\">u4\")],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorized version of previous attempt. \n",
    "%timeit np.vectorize(ibmpython)(np.frombuffer(data,dtype='>u4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses the current industry method of segyio module\n",
    "offset = 3600 + 10001 * (240 + (samples_per_trace * 4))\n",
    "d = np.memmap('Kerry3D.segy', offset = offset, dtype = np.uint32)\n",
    "%timeit segyio.tools.native(d[240:240+samples_per_trace])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uses pypi module ibm2ieee which is cython under the hood. https://pypi.org/project/ibm2ieee/\n",
    "%timeit i2f(np.frombuffer(data,dtype=\">u4\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses a numba vectorized version of the python function. effectively precompiles to machine code.\n",
    "%timeit ibmpy_vec(np.frombuffer(data,dtype='>u4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses cupy with a raw kernel wriiten in cuda. memory output must be preallocated\n",
    "x1 = cp.array(np.frombuffer(data,dtype='>u4'),dtype=cp.uint32)\n",
    "arr = cp.zeros(x1.size, dtype=cp.float32)\n",
    "%timeit ibm32cupy((x1.size,), (1,), (x1, arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = np.array([ibmpython(x) for x in np.frombuffer(data,dtype=\">u4\")],dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum((ans - np.vectorize(ibmpython)(np.frombuffer(data,dtype='>u4')))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum((ans - segyio.tools.native(d[240:240+samples_per_trace],format=1))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum((ans - i2f(np.frombuffer(data,dtype=\">u4\")))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum((ans - ibmpy_vec(np.frombuffer(data,dtype='>u4')))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.sum((cp.array(ans,dtype=cp.float32) - arr)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[239:240+samples_per_trace][:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.frombuffer(data,dtype=\">u4\")[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'ibm2float32' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3f2a7cfa824b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mi2f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1605997759\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'ibm2float32' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "i2f(np.array([1605997759,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('numba': conda)",
   "language": "python",
   "name": "python38564bitnumbaconda7a7e672d51f74b89a6810c98e8254942"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
